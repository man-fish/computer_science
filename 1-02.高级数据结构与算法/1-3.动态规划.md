## 前言✍

动态规划`（Dynamic Programming）`，求解的问题必须有两个性质：`最优子结构`和`子问题重叠`，和分治法的思想相同，动态规划的思路也是先将大问题分解成若干个规模相同的子问题，但是动态规划的问题是重叠的，想要理解一个动态规划就要理解一个它的核心，动态规划算法的核心是下面的一张图片和一个小故事。

<img src="http://image.innoweb.cn/2020-01-31-002214.png" alt="img" style="zoom:75%;" />

```
A :  "1+1+1+1+1+1+1+1 =？" 
A :  "上面等式的值是多少"
B :  "8!"
A :  在上面等式的左边写上 "1+"
A :  "此时等式的值为多少"
B :  (quickly) "9!"
A :  "你怎么这么快就知道答案了"
A :  "只要在8的基础上加1就行了"
A :  "所以你不用重新计算,因为你记住了第一个等式的值为8!
-->   动态规划算法也可以说是 '记住求过的解来节省时间'。
```

由上面的图片和小故事可以知道动态规划算法的核心就是记住已经解决过的子问题的解，动态规划通过备忘录来解决子问题重叠。

## **动态规划套路**👉

动态规划遵循一套固定的流程：**状态转移方程-> 递归的暴力解法 -> 带备忘录的递归解法 -> 非递归的动态规划解法**。这个过程是层层递进的解决问题的过程，以下，先通过两个个比较简单的例子：斐波那契和凑零钱问题，揭开动态规划的神秘面纱，描述上述三个流程。后续还会写几篇文章探讨如何使用动态规划技巧解决比较复杂的经典问题。

- **根据问题写出状态转移方程**
- **递归的暴力解法（选取最子结构）**
- **自顶向下的备忘录法（递归）** 
- **自底向上的动态规划**



## 斐波那契数🏹

为了说明动态规划的这两种方法，举一个最简单的例子：求斐波拉契数列**Fibonacci** 。严格的说斐波那契数列并不算是一个动态规划问题，但是它却能很好的诠释子问题重叠。

```go
Fibonacci (n) = 1;   n = 0
Fibonacci (n) = 1;   n = 1
Fibonacci (n) = Fibonacci(n-1) + Fibonacci(n-2)
```

### 状态转移方程🚢

这里，引出 **「状态转移方程」** 这个名词，实际上就是描述问题结构的数学形式：

![C9D0E6E6677312E7CB2E80D2AF762EFC](http://image.innoweb.cn/2020-01-31-010405.png)

为啥叫**「状态转移方程」**？为了听起来高端。你把 f(n) 想做一个状态 n，这个状态 n 是由状态 n - 1 和状态 n - 2 相加转移而来，这就叫状态转移，仅此而已。

就具体问题而言，f(n)表示问题的最优解，n表示总问题的量，比如说斐波那契中：f(n) 表示要求的斐波那契数，  n表示第i个斐波那契数。

你会发现，上面的几种解法中的所有操作，都是围绕这个方程式的不同表现形式。可见列出「状态转移方程」的重要性，它是解决问题的核心。很容易发现，其实状态转移方程直接代表着暴力解法。**千万不要看不起暴力解，动态规划问题最困难的就是写出状态转移方程，即这个暴力解**。优化方法无非是用备忘录或者 DP table，再无奥妙可言。

### 暴力递归🏭

这个算法使用递归十分的简单。先使用递归版本来实现这个算法：

```go
func fib(n int) int{
    if n<=0 {
        return 0
    }
    if n==1 {
        return 1        
    }
	return fib(n-1) + fib(n-2)
}
//输入6 -> 输出：8
```

先来分析一下递归算法的执行流程，假如输入6，那么执行的递归树如下：

![9F611BC27714929F4EEC9CC0A03EAD9E](http://image.innoweb.cn/2020-06-25-124306.png)

**PS**：**但凡遇到需要递归的问题，最好都画出递归树，这对你分析算法的复杂度，寻找算法低效的原因都有巨大帮助。**

上面的递归树中的每一个子节点都会执行一次，很多重复的节点被执行，fib(2)被重复执行了5次。由于调用每一个函数的时候都要保留上下文，所以空间上开销也不小。这么多的子节点被重复执行，如果在执行的时候把执行过的子节点保存起来，后面要用到的时候直接查表调用的话可以节约大量的时间。下面就看看动态规划的两种方法怎样来解决斐波拉契数列Fibonacci 数列问题。

### 自顶而下的备忘录递归解法🚞

备忘录法也是比较好理解的，创建了一个n+1大小的数组来保存求出的斐波拉契数列中的每一个值，在递归的时候如果发现前面fib（n）的值计算出来了就不再计算，如果未计算出来，则计算出来后保存在Memo数组中，下次在调用fib（n）的时候就不会重新递归了。之所以要用容量为n+1的数组是因为我们输入的**index**不是真正的**index**，而**index+1**。

```go
func fib (n int) int {
	if n <= 0 {
		return n
	}
	arr := make([]int ,n+1)
	for idx := range arr {
		arr[idx] = -1
	}
	return fibDypBackward(arr,n)
}

func fibDypBackward(arr []int, n int) int {
	if arr[n] != -1 {
		return arr[n]
	}
	if n <= 2 {
		return 1
	}
	arr[n] = fibDypBackward(arr, n-1) + fibDypBackward(arr, n-2)
	return arr[n]
}
```

比如上面的递归树中在计算fib（6）的时候先计算fib（5），调用fib（5）算出了fib（4）后，fib（6）再调用fib（4）就不会在递归fib（4）的子树了，因为fib（4）的值已经保存在Memo[4]中。

解决一个子问题的时间，同上，没有什么循环，时间为 O(1)。所以，本算法的时间复杂度是 O(n)。比起暴力算法，是降维打击。

> [至此，带备忘录的递归解法的效率已经和动态规划一样了。实际上，这种解法和动态规划的思想已经差不多了，只不过这种方法叫做**「自顶向下」**，动态规划叫做**「自底向上」**。]()
>
> - 啥叫**「自顶向下」**？注意我们刚才画的递归树（或者说图），是从上向下延伸，都是从一个规模较大的原问题比如说 f(20)，向下逐渐分解规模，直到 f(1) 和 f(2) 触底，然后逐层返回答案，这就叫「自顶向下」。
> - 啥叫**「自底向上」**？反过来，我们直接从最底下，最简单，问题规模最小的 f(1) 和 f(2) 开始往上推，直到推到我们想要的答案 f(20)，这就是动态规划的思路，这也是为什么动态规划一般都脱离了递归，而是由循环迭代完成计算。

### 自上而下的动态规划🚈

备忘录法还是利用了递归，上面算法不管怎样，计算fib（6）的时候最后还是要计算出`fib(1)，fib(2)，fib(3)`,那么何不先计算出`fib(1)，fib(2)，fib(3)`呢？这也就是动态规划的核心，先计算子问题，再由子问题计算父问题。

```go
func fibDyp(n int) int {
	if n <= 0 {
		return n
	}
	arr := make([]int ,n+1)
	arr[1] = 1
	for i := 3; i <= n; i++ {
		arr[i] = arr[i-1] + arr[i-2]
	}
	return arr[n]
}
```

![EBAA0C269F4CE402575CD45D805F0D41](http://image.innoweb.cn/2020-01-31-010350.png)

实际上，带备忘录的递归解法中的「备忘录」，最终完成后就是这个 DP table，所以说这两种解法其实是差不多的，大部分情况下，效率也基本相同。



## 凑零钱问题🌉

刚刚的斐波那契数列并不能很好的诠释最优子结构这个特点，接下来我们用另一道经典的例题来描述一下。

**题目**：给你 `k` 种面值的硬币，面值分别为 `c1, c2 ... ck`，再给一个总金额 `n`，问你最少需要几枚硬币凑出这个金额，如果不可能凑出，则回答 `-1` 。比如说，k = 3，面值分别为 1，2，5，总金额 n = 11，那么最少需要 3 枚硬币，即 11 = 5 + 5 + 1 。下面走流程。

那么下面我们开始解答：

### 状态转移方程🚏

![000A1E3A5A22E6C81EBF3248B4317CE8](http://image.innoweb.cn/2020-01-31-010415.png)

其实，这个方程就用到了「最优子结构」性质：原问题的解由子问题的最优解构成。即 `f(11)` 由 `f(10), f(9), f(6)` 的最优解转移而来。

就具体问题而言，f(n)表示问题的最优解，n表示总问题的量，比如说此问题中：f(n) 表示要多少次，  n表示剩余要凑的金额。

记住，要符合「最优子结构」，**子问题间必须互相独立**。什么叫相互独立？对于这个零钱问题来说，我们处理 `f(10), f(9), f(6)`他们之间都是毫无关系的，没有相互制约，而是互相独立的。所以这个状态转移方程是可以得到正确答案的。

### 暴力递归🎲

拿到状态转移方程之后我们就可以书写递归的程序，要做递归一定要画递归树，太重要了。

```go
func coinCharge(coins []int, account int) int {
	if account == 0 {
		return 0
	}

	ans := math.MaxInt64

	for _, coin := range coins {	        
		if account - coin < 0 {continue}					/*当凑不齐的时候可以看到我们是不分支的*/
		subPro := coinCharge(coins,account-coin)	/*构造递归树中的同级的三种情况*/
		if subPro == -1 {continue}					     	/*当子程序不能不能凑整的时候我们也跳过这个分支*/
		ans = int(math.Min(float64(ans),float64(subPro)+1))	/*本轮比较*/
	}

	if ans == math.MaxInt64 {
		return -1
	}else{
		return ans
	}
}
```

### 带备忘录的递归算法👩‍💻

```go
func coinMemorizeCharge(coins []int, memory []int, account int) int {
	if memory[account] != -2 {
		return memory[account]
	}
	if account == 0 {
		return 0
	}
	ans := math.MaxInt64
	for _,coin := range coins {
		if account - coin < 0 {
			continue
		}
		pre := coinMemorizeCharge(coins,memory,account-coin)
		if pre == -1 {
			continue
		}
		ans = int(math.Max(float64(pre)+1,float64(ans)))
	}

	if ans != math.MaxInt64 {
		memory[account] = ans
		return ans
	}else{
		return -1
	}
}
```

很显然「备忘录」大大减小了子问题数目，完全消除了子问题的冗余，所以子问题总数不会超过金额数 n，即子问题数目为 O(n)。处理一个子问题的时间不变，仍是 O(k)，所以总的时间复杂度是 O(kn)。

### 动态规划🎐

```go
func coinDynamiccharge(coins []int, account int) int {
	dp := make([]int, account+1)
	for  j := 1; j < len(dp); j++  {
		dp[j] = -1
	}

	for i := 1; i <= account; i++ {
		for _,coin := range coins {
			if coin <= i {
				dp[i] = int(math.Min(float64(dp[i]),float64(dp[i-coin]+1)))
			}
		}
	}
	if dp[account] == -1 {
		return -1
	}else{
		return dp[account]
	}
}
```

![375BD02DAF85B3E692532BB820CEE7EC](http://image.innoweb.cn/2020-01-31-010431.png)

计算机解决问题其实没有任何奇技淫巧，它唯一的解决办法就是穷举，穷举所有可能性。算法设计无非就是先思考“如何穷举”，然后再追求“如何聪明地穷举”。

列出动态转移方程，就是在解决“如何穷举”的问题。之所以说它难，一是因为很多穷举需要递归实现，二是因为有的问题本身的解空间复杂，不那么容易穷举完整。

备忘录、DP 就是在追求“如何聪明地穷举”。用空间换时间的思路，是降低时间复杂度的不二法门，除此之外，试问，还能玩出啥花活？

## 动态规划原理🥜

虽然已经用动态规划方法解决了上面两个问题，但是大家可能还跟我一样并不知道什么时候要用到动态规划。总结一下上面的斐波拉契数列和钢条切割问题，发现两个问题都涉及到了重叠子问题，和最优子结构。

#### ①最优子结构

用动态规划求解最优化问题的第一步就是刻画最优解的结构，如果一个问题的解结构包含其子问题的最优解，就称此问题具有最优子结构性质。因此，某个问题是否适合应用动态规划算法，它是否具有最优子结构性质是一个很好的线索。使用动态规划算法时，用子问题的最优解来构造原问题的最优解。因此必须考查最优解中用到的所有子问题。

#### ②重叠子问题

在斐波拉契数列和钢条切割结构图中，可以看到大量的重叠子问题，比如说在求fib（6）的时候，fib（2）被调用了5次，在求cut（4）的时候cut（0）被调用了4次。如果使用递归算法的时候会反复的求解相同的子问题，不停的调用函数，而不是生成新的子问题。如果递归算法反复求解相同的子问题，就称为具有重叠子问题（overlapping subproblems）性质。在动态规划算法中使用数组来保存子问题的解，这样子问题多次求解的时候可以直接查表不用调用函数递归。

