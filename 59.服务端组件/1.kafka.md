## 什么叫消息队列💩

消息（`Message`）是指在应用间传送的数据。消息可以非常简单，比如只包含文本字符串，也可以更复杂，可能包含嵌入对象。

消息队列（`Message Queue`）是一种应用间的通信方式，消息发送后可以立即返回，由消息系统来确保消息的可靠传递。消息发布者只管把消息发布到 `MQ` 中而不用管谁来取，消息使用者只管从 MQ 中取消息而不管是谁发布的。这样发布者和使用者都不用知道对方的存在，他们共享的只是消息队列的名称而已。

## 为何用消息队列🗾

### 异步处理

参照下图利用消息队列把业务流程中的非关键流程异步化，从而显著降低业务请求的响应时间。

![nsq应用场景1](http://image.innoweb.cn/2020-02-07-190627.png)

### 应用解耦

通过使用消息队列将不同的业务逻辑解耦，降低系统间的耦合，提高系统的健壮性。后续有其他业务要使用订单数据可直接订阅消息队列，提高系统的灵活性。![nsq应用场景1](http://image.innoweb.cn/2020-02-07-190719.png)

### 流量削峰

类似秒杀（大秒）等场景下，某一时间可能会产生大量的请求，使用消息队列能够为后端处理请求提供一定的缓冲区，保证后端服务的稳定性。![nsq应用场景1](http://image.innoweb.cn/2020-02-07-190727.png)

## Kafka

### 介绍 

Kafka是一个分布式数据流平台，可以运行在单台服务器上，也可以在多台服务器上部署形成集群。它提供了发布和订阅功能，使用者可以发送数据到Kafka中，也可以从Kafka中读取数据(以便进行后续的处理)。Kafka具有高吞吐、低延迟、高容错等特点。

Apache Kafka由著名职业社交公司LinkedIn开发，最初是被设计用来解决LinkedIn公司内部海量日志传输等问题。Kafka使用Scala语言 编写，于201 1年开源并进入Apache孵化器，2012年10月正式毕业， 现在为Apache顶级项目。

>  kafka就相当于我们说的queue集群

### 概念

- Kafka作为一个集群，运行在一台或者多台服务器上.
- Kafka 通过 *topic* 对存储的流数据进行分类。
- 每条记录中包含一个key，一个value和一个timestamp（时间戳）。

### 组成

![image-20200208033024243](http://image.innoweb.cn/2020-02-07-200508.png) 

- **Producer:** Producer即生产者，消息的产生者,是消息的入口。

- **kafka cluster**: kafka集群， 1台或多台服务器组成

  - **Broker:** Broker是指部署了Kafka实例的服务器节点。每个服务器.上有一个或多个kafka的实例，我们姑且认为每个broker对应1台服务器。每个kafka集群内的broker都有1个不重复的编号，如图中的broker-0、broker-1等....

  - **Topic:** 消息的主题，可以理解为消息的分类，kafka的数据就保存在topic。 在每个broker上都可以创建多个topic。实际应用中通常是一个业务线建一个topic。

  - **Partition:** Topic的分区， 每个topic可以有多个分区，分区的作用是做负载，提高kafka的吞吐量。同一个topic在不同的分区的数据是不重复的，partition的表现形式就是一个一个的文件夹!

  - **Replication**:每一个分区都有多个副本，副本的作用是做备胎。当主分区(Leader) 故障的时候会选择一个备胎(Follower), 上位， 成为Leader。 在kafka中默认副本的最大数量是10个，且副本的数量不能大于Broker的数量，follower和leader绝对是 在不同的机器，同一机器对同一个分区也只可能存放一个副本(包括自己)。 

- **Consumer**:消费者，即消息的消费方，是消息的出口。
  - **Consumer Group:**我们可以将多个消费组组成一个消费者组，在kafka的设计中同一个分区的数据只能被消费者组中的某1个消费者消费。同一个消费者组的消费者可以消费同1个topic的不同分区的数据，这也是为了提高kafka的吞吐量!

### 工作流程

我们看上面的架构图中，producer就是生产者， 是数据的入口。Producer在写 入数据的时候会把数据写入到leader中，不会直接将数据写入follower!那leader怎 么找呢?写入的流程又是什么样的呢?我们看下图:

![image-20200208033937292](http://image.innoweb.cn/2020-02-07-193940.png) 

1. 生产者从Kafka集群获取分区leader信息 

2. 生产者将消息发送给leader

3. leader将消息写入本地磁盘

4. follower从leader拉取消息数据 

5. follower将消息写入本地磁盘后向leader发送ACK

6. leader收到所有的follower的ACK之后向生产者发送ACK

### 选择partition的原则

那在kafka中，如果某个topic有多个partition, producer又怎么知道该将数据发往哪个partition呢?kafka中有几个原则:

1. partition在写入的时候可以指定需要写入的partition, 如果有指定，则写入对应的partition。

2. 如果没有指定partition, 但是设置了数据的key,则会根据key的值hash出- - -个partition。 

3. 如果既没指定partition, 又没有设置key,则会采用轮询方式，即每次取-小段时间的数据写入某个partition，下一小段的时间写入下一个partition。

> 前提是我们设置了多个partition。

### ACK应答机制

producer在向kafka写入消息的时候，可以设置参数来确定是否确认kafka接收到数据，这个参数可设置的值为`0、1、all`。

- 0代表producer往集群发送数据不需要等到集群的返回，不确保消息发送成功。安全性最低但是效率最高。

- 1代表producer往集群发送数据只要leader应答就可以发送下一 条，只确保leader接收成功。

- all代表producer往集 群发送数据需要所有的follower都完成从leader的同步才会发送下一条,确保leader发送成功和所有的副本都完成备份。安全性最高，但是效率最低。

> 最后要注意的是，如果往不存在的topic写数据，kafka会 自动创建topic, partition和replication的数量默认配置都是1。 

### Topic和数据日志

topic是同1类别的消息记录(record) 的集合。在Kafka中， 一个主题通常有多个订阅者。对于每个主题，Kafka集群维护了一个分区数据日志文件结构如下:

![image-20200208034618236](http://image.innoweb.cn/2020-02-07-194622.png)

 

每个partition都是一个有序并且不可变的消息记录集合。当新的数据写入时，就被追加到partition的末尾。在每个partition中，每条消息都会被分配一个顺序的唯一 标识，这个标识被称为offset, 即偏移量。注意，Kafka只保证在同一个partition内部消息是有序的，在不同partition之间，并不能保证消息有序。

### Partition结构 

Partition在服务器上的表现形式就是一个一个的文件夹，文件夹位置为kafka中配置的位置，每个partition的文件夹下面会有多组segment文件，每组segment文件又包含. index文件、. 1og文件、. timeindex文件三个文件，其中.1og文件就是实际存储message的地方，而. index和. timeindex文件为索引文件，用于检索消息。

<img src="http://image.innoweb.cn/2020-02-07-225239.png" alt="image-20200208065231973" style="zoom:50%;" />

### 消费数据

多个消费者实例可以组成一介消费者组，并用一个标签来标识这个消费者组。

一个消费者组中的不同消费者实例可以运行在不同的进程甚至不同的服务器上。

 如果所有的消费者实例都在同一个消费者组中，那么消息记录会被很好的均衡的发送到每个消费者实例。

如果所有的消费者实例都在不同的消费者组，那么每一条消息记录会被广播到每1个消费者实例。

![image-20200208035228677](http://image.innoweb.cn/2020-02-07-200443.png)

 

举个例子，如上图所示一个两个节点的Kafka集群上拥有-个四个partition (PO-P3) 的topic。 有两个消费者组都在消费这个topic中的数据，消费者组A有两个消费者实例，消费者组B有四个消费者实例。从图中我们可以看到，在同一个消费者组中，每个消费者实例可以消费多个分区，但是每个分区最多只能被消费者组中的一个实例消费。也就是说，如果有一个4个分区的主题，那么消费者组中最多只能有4个消费者实例去消费，多出来的都不会被分配到分区。其实这也很好理解，如果允许两个消费者实例同时消费同一个分区，那么就无法记录这个分区被这个消费者组消费的offset了。如果在消费者组中动态的上线或下线消费者，那么Kafka集群会自动调整分区与消费者实例间的对应关系。

### Kafka有四个核心的API:

- The [Producer API](http://kafka.apachecn.org/documentation.html#producerapi) 允许一个应用程序发布一串流式的数据到一个或者多个Kafka topic。
- The [Consumer API](http://kafka.apachecn.org/documentation.html#consumerapi) 允许一个应用程序订阅一个或多个 topic ，并且对发布给他们的流式数据进行处理。
- The [Streams API](http://kafka.apachecn.org/documentation/streams) 允许一个应用程序作为一个*流处理器*，消费一个或者多个topic产生的输入流，然后生产一个输出流到一个或多个topic中去，在输入输出流中进行有效的转换。
- The [Connector API](http://kafka.apachecn.org/documentation.html#connect) 允许构建并运行可重用的生产者或者消费者，将Kafka topics连接到已存在的应用程序或者数据系统。比如，连接到一个关系型数据库，捕捉表（table）的所有变更内容。

### Kafka配置

```properties
############################# Server Basics #############################
#	broker id kafka在集群里的broker id
broker.id=0

############################# Log Basics #############################
# A comma separated list of directories under which to store log files，日志文件夹
log.dirs=/usr/local/var/lib/kafka-logs

# the brokers. partition分区数
num.partitions=1

############################# Zookeeper #############################
# Zookeeper connection string (see zookeeper docs for details). zookkeeper 端口
zookeeper.connect=localhost:2181

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=6000
```

### 命令行

启动

```bash
zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties & kafka-server-start /usr/local/etc/kafka/server.properties
```

将消费打到命令行

```bash
kafka-console-consumer --bootstrap-server=127.0.0.1:9092 --topic=web_log --from-beginning
```



## go操作kafka

### sarama

Go语言中连接kafka使用第三方库:[github.com/Shopify/sarama](https://github.com/Shopify/sarama)。

### 下载及安装

```bash
go get github.com/Shopify/sarama
```

### 注意事项

`sarama` v1.20之后的版本加入了`zstd`压缩算法，需要用到cgo，在Windows平台编译时会提示类似如下错误：

```bash
# github.com/DataDog/zstd
exec: "gcc":executable file not found in %PATH%
```

所以在Windows平台请使用v1.19版本的sarama。

### 连接kafka发送消息

```go
import (
	"fmt"
	"github.com/Shopify/sarama"
)

var (
	client sarama.SyncProducer
)

///

func Init(addrs ...string) (err error) {
	//配置kafka
	config := sarama.NewConfig()  //生成配置通过属性赋值的方式修改
	config.Producer.RequiredAcks = sarama.WaitForAll
	// 对应kafka的应答机制的三个状态码，这里我们等待所有的follower都同步完成之后producer再发送下一条。
	config.Producer.Partitioner = sarama.NewRandomPartitioner
	// 以轮询的方式随机写入partitioner
	config.Producer.Return.Successes = true
	// 成功交付的信息再channel中返回

	client, err = sarama.NewSyncProducer(addrs,config)
	// 这里接受一个ip地址的切片，相当于是一个集群
	if err != nil {
		fmt.Println("Producer closed, err:", err)
		return
	}
	return
}

func SendToKafka(topic, data string) {
	//构造消息
	msg := &sarama.ProducerMessage{}
	msg.Topic = topic
	msg.Value = sarama.StringEncoder(data)

	//发送消息
	pid, offset, err := client.SendMessage(msg)
	if err != nil {
		fmt.Println("send msg failed, err:",err)
	}
	fmt.Printf("pid: %v	offset: %v\n", pid, offset)
}
//main.go
func main(){
	err = kafka.Init([]string{cfg.Address}...)
	if err != nil {
		fmt.Printf("Init kafka fail, err:%v",err)
		return
	}
	for {
		select {
			case line := <-tailLog.ReadLog():
				kafka.SendToKafka(topic,line.Text)
			default:
				time.Sleep(time.Second)
		}
	}
}
```